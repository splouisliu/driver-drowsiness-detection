{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.transforms = transforms.Compose([transforms.Resize([24, 24]),\n",
    "                                              transforms.ToTensor()]) \n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "\n",
    "        # Traverses all subfolders and stores the path and label of each training example\n",
    "        subfolders = os.listdir(path)\n",
    "        for folder in subfolders:\n",
    "            p = os.path.join(path, folder)\n",
    "\n",
    "            if os.path.isdir(p):                                                    # ignores documentation files\n",
    "                imgs = os.listdir(p)\n",
    "\n",
    "                for file_name in imgs:\n",
    "                    self.img_paths.append(os.path.join(p, file_name))               # append image path\n",
    "                    self.img_labels.append(int(file_name.split(\"_\")[4]))            # append eye state label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert(\"RGB\") \n",
    "        img = self.transforms(img)\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        return (img, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object\n",
    "dataset = MRLDataset(\".\\MRL\")       # Pass in root folder of dataset\n",
    "\n",
    "# Random split (60-20-20)\n",
    "n = len(dataset)\n",
    "n_train = int(0.6 *n)\n",
    "n_valid = int(0.2 *n)\n",
    "n_test = n - n_train - n_valid\n",
    "\n",
    "[train_set, valid_set, test_set] = torch.utils.data.random_split(dataset, [n_train, n_valid, n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 5)\n",
    "        self.fc1 = nn.Linear(90, 24)\n",
    "        self.fc2 = nn.Linear(24, 1)\n",
    "\n",
    "    def forward(x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 90)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion = None):\n",
    "    total_losses = 0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    for i, [inputs, labels] in enumerate(loader):\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Track total loss\n",
    "        if criterion:\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_losses += loss.item()\n",
    "\n",
    "        # Track total correct\n",
    "        pred = outputs.argmax(dim = 1)\n",
    "        total_correct += pred.eq(labels).sum().item()\n",
    "        total_examples += inputs.shape[0]\n",
    "\n",
    "    if criterion:\n",
    "        return total_losses/(i+1), total_correct/total_examples \n",
    "    else:\n",
    "        return total_correct/total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, valid_data, learning_rate = 0.001, batch_size = 64, num_epochs = 10):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    iters, train_losses, valid_losses, train_acc, valid_acc = [], [], [], [], []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)                     # forward pass\n",
    "\n",
    "            loss = criterion(outputs, labels)           # calculate loss\n",
    "            loss.backward()                             # calculate gradients using backprop\n",
    "            optimizer.step()                            # apply optimizer step\n",
    "            optimizer.zero_grad()                       # zero the gradients\n",
    "\n",
    "        # Calculate and record loss/accuracy values\n",
    "        [l, a] = evaluate(model, train_loader, criterion)\n",
    "        train_losses.append(l)\n",
    "        train_acc.append(a)\n",
    "\n",
    "        [l, a] = evaluate(model, valid_loader, criterion)\n",
    "        valid_losses.append(l)\n",
    "        valid_acc.append(a)\n",
    "\n",
    "        iters.append(epoch)\n",
    "\n",
    "    # Plot training curves\n",
    "    plt.title(\"Training Curve - Loss\")\n",
    "    plt.plot(iters, train_losses, label = \"Training\")\n",
    "    plt.plot(iters, valid_losses, label = \"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Loss: {}\".format(train_losses[-1]))\n",
    "    print(\"Final Validation Loss: {}\".format(valid_losses[-1]))\n",
    "    print()\n",
    "\n",
    "    plt.title(\"Training Curve - Accuracy\")\n",
    "    plt.plot(iters, train_acc, label = \"Training\")\n",
    "    plt.plot(iters, valid_acc, label = \"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(valid_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EyeClassifier()\n",
    "\n",
    "train(model, train_set, valid_set)"
   ]
  }
 ]
}