{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import time\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 512)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EyeClassifier(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Load  pre-trained MTCNN face detector\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Load pre-trained landmark predictor\n",
    "predictor = dlib.shape_predictor(\"../Pretrained Detectors/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load CNN eye classifier\n",
    "eye_model = EyeClassifier()\n",
    "eye_model.load_state_dict(torch.load(\"../Saved Models/model2.pt\"))\n",
    "eye_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locates bounding box for a single face\n",
    "def detect_face(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    face_model.setInput(blob)\n",
    "    detections = face_model.forward()\n",
    "\n",
    "    (x1, y1, x2, y2) = 0, 0, 0, 0\n",
    "    max_confidence = 0\n",
    "\n",
    "    for i in range(detections.shape[2]):                          \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5 and confidence > max_confidence:      # Only considers predictions with > 0.5 confidence\n",
    "            (h, w) = img.shape[:2]\n",
    "            x1 = int(detections[0, 0, i, 3] * w)\n",
    "            y1 = int(detections[0, 0, i, 4] * h)\n",
    "            x2 = int(detections[0, 0, i, 5] * w)\n",
    "            y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "            max_confidence = confidence                           # If multiple faces are detected, only return the one with highest confidence\n",
    "\n",
    "    return dlib.rectangle(x1, y1, x2, y2), max_confidence\n",
    "\n",
    "\n",
    "# Locates bounding box for a single eye\n",
    "def detect_eye(img, face):\n",
    "    landmarks = predictor(img, face)\n",
    "\n",
    "    if landmarks.num_parts == 0:\n",
    "        return (0, 0, 0, 0), False\n",
    "    \n",
    "    \"\"\" Below is some random math I came up with to turn LEFT eye landmarks into a square box, feel free to change\"\"\"\n",
    "    \n",
    "    x1 = landmarks.part(17).x                   \n",
    "    x2 = landmarks.part(21).x\n",
    "    d = abs(x2-x1)\n",
    "    k = d * 0.05\n",
    "\n",
    "    x1 = x1 - int(k/2)\n",
    "    x2 = x2 + int(k/2)\n",
    "    y1 = landmarks.part(19).y - int(k/2)\n",
    "    y2 = y1 + int(d+k)\n",
    "    \n",
    "    \"\"\"\n",
    "    x1 = landmarks.part(36).x                   \n",
    "    x2 = landmarks.part(39).x\n",
    "    d = abs(x2-x1)\n",
    "    k = d * 0.9\n",
    "\n",
    "    x1 = x1 - int(k/2)\n",
    "    x2 = x2 + int(k/2)\n",
    "    y1 = landmarks.part(36).y - int((d+k)/2)\n",
    "    y2 = landmarks.part(36).y + int((d+k)/2)\n",
    "    \"\"\"\n",
    "\n",
    "    return (x1, y1, x2, y2), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares an image for CNN eye classifier\n",
    "def preprocess(img):\n",
    "    t = transforms.Compose([transforms.Resize([24, 24]), \n",
    "                            transforms.ToTensor()]) \n",
    "                            \n",
    "    img = Image.fromarray(img).convert(\"L\")\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = t(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# Predicts eye state given a single 1x24x24 tensor\n",
    "def predict_eye_state(img):\n",
    "    outputs = eye_model(img.unsqueeze(0))\n",
    "    prob = F.softmax(outputs, dim = 1)\n",
    "    pred = outputs.argmax(dim = 1).item()\n",
    "\n",
    "    #print(f\"Probabilities: ({prob[0][0]}, {prob[0][1]})\")\n",
    "    #print(\"Prediction:\", pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13403010368347168\n",
      "0.07101631164550781\n",
      "0.07001590728759766\n",
      "0.08301901817321777\n",
      "0.07501721382141113\n",
      "0.0780172348022461\n",
      "0.09002113342285156\n",
      "0.08301806449890137\n",
      "0.06801557540893555\n",
      "0.07301640510559082\n",
      "0.0670156478881836\n",
      "0.06501460075378418\n",
      "0.06601476669311523\n",
      "0.06601476669311523\n",
      "0.07101631164550781\n",
      "0.07001543045043945\n",
      "0.06401371955871582\n",
      "0.07001566886901855\n",
      "0.07701778411865234\n",
      "0.089019775390625\n",
      "0.06401419639587402\n",
      "0.06601524353027344\n",
      "0.0690147876739502\n",
      "0.0690155029296875\n",
      "0.07701802253723145\n",
      "0.07301664352416992\n",
      "0.07701754570007324\n",
      "0.08701944351196289\n",
      "0.07001590728759766\n",
      "0.09103012084960938\n",
      "0.08201861381530762\n",
      "0.0780181884765625\n",
      "0.07401657104492188\n",
      "0.06601524353027344\n",
      "0.06601452827453613\n",
      "0.07701754570007324\n",
      "0.07601714134216309\n",
      "0.07501745223999023\n",
      "0.07601737976074219\n",
      "0.08101797103881836\n",
      "0.07001686096191406\n",
      "0.07301688194274902\n",
      "0.0780179500579834\n",
      "0.07201647758483887\n",
      "0.07201623916625977\n",
      "0.08802056312561035\n",
      "0.08101820945739746\n",
      "0.08301925659179688\n",
      "0.07701706886291504\n",
      "0.08501935005187988\n",
      "0.07901787757873535\n",
      "0.07901763916015625\n",
      "0.07701730728149414\n",
      "0.07501697540283203\n",
      "0.07901787757873535\n",
      "0.07501721382141113\n",
      "0.10302352905273438\n",
      "0.0870201587677002\n",
      "0.08401775360107422\n",
      "0.08201885223388672\n",
      "0.0690147876739502\n",
      "0.06601476669311523\n",
      "0.06401443481445312\n",
      "0.07001543045043945\n",
      "0.07901740074157715\n",
      "0.07301664352416992\n",
      "0.06801509857177734\n",
      "0.07501721382141113\n",
      "0.07001543045043945\n",
      "0.06801557540893555\n",
      "0.07201671600341797\n",
      "0.07701706886291504\n",
      "0.07201647758483887\n",
      "0.06501483917236328\n",
      "0.07701706886291504\n",
      "0.07601714134216309\n",
      "0.07201671600341797\n",
      "0.09002137184143066\n",
      "0.07201719284057617\n",
      "0.06601500511169434\n",
      "0.07201504707336426\n",
      "0.07901763916015625\n",
      "0.06601524353027344\n",
      "0.06801509857177734\n",
      "0.06501507759094238\n",
      "0.06801509857177734\n",
      "0.07001614570617676\n",
      "0.07201671600341797\n",
      "0.06801533699035645\n",
      "0.06601452827453613\n",
      "0.0690157413482666\n",
      "0.062013864517211914\n",
      "0.06801557540893555\n",
      "0.07201671600341797\n",
      "0.06701469421386719\n",
      "0.0690159797668457\n",
      "0.07201600074768066\n",
      "0.06601524353027344\n",
      "0.06801509857177734\n",
      "0.06801557540893555\n",
      "0.06401371955871582\n",
      "0.06401467323303223\n",
      "0.0690152645111084\n",
      "0.06601524353027344\n",
      "0.06701445579528809\n",
      "0.0690157413482666\n",
      "0.0670158863067627\n",
      "0.06401467323303223\n",
      "0.06501483917236328\n",
      "0.06001400947570801\n",
      "0.06401419639587402\n",
      "0.0690150260925293\n",
      "0.06701493263244629\n",
      "0.07001566886901855\n",
      "0.07101607322692871\n",
      "0.06701493263244629\n",
      "0.06701540946960449\n",
      "0.06501483917236328\n",
      "0.06701540946960449\n",
      "0.07601737976074219\n",
      "0.07501721382141113\n",
      "0.06801486015319824\n",
      "0.07501697540283203\n",
      "0.07501673698425293\n",
      "0.06601500511169434\n",
      "0.06801486015319824\n",
      "0.06601500511169434\n",
      "0.08201861381530762\n",
      "0.06701517105102539\n",
      "0.07301688194274902\n",
      "0.07001614570617676\n",
      "0.06702733039855957\n",
      "0.06501460075378418\n",
      "0.06501436233520508\n",
      "0.06601572036743164\n",
      "0.08201909065246582\n",
      "0.0690152645111084\n",
      "0.062014102935791016\n",
      "0.06701517105102539\n",
      "0.07001590728759766\n",
      "0.0690150260925293\n",
      "0.07001566886901855\n",
      "0.06501483917236328\n",
      "0.08401870727539062\n",
      "0.0690155029296875\n",
      "0.0690157413482666\n",
      "0.06601476669311523\n",
      "0.0690157413482666\n",
      "0.06801581382751465\n",
      "0.06701540946960449\n",
      "0.07101655006408691\n",
      "0.06701469421386719\n",
      "0.06801581382751465\n",
      "0.07101583480834961\n",
      "0.06401419639587402\n",
      "0.06601452827453613\n",
      "0.07401704788208008\n",
      "0.06801509857177734\n",
      "0.07001590728759766\n",
      "0.07101583480834961\n",
      "0.06701540946960449\n",
      "0.062014102935791016\n",
      "0.06601524353027344\n",
      "0.06501531600952148\n",
      "0.06401419639587402\n",
      "0.06401467323303223\n",
      "0.06501483917236328\n",
      "0.06801533699035645\n",
      "0.0670156478881836\n",
      "0.06601500511169434\n",
      "0.08301925659179688\n",
      "0.08201861381530762\n",
      "0.06701540946960449\n",
      "0.06801557540893555\n",
      "0.07201623916625977\n",
      "0.06601500511169434\n",
      "0.06701493263244629\n",
      "0.07601690292358398\n",
      "0.0690157413482666\n",
      "0.07101583480834961\n",
      "0.07101631164550781\n",
      "0.06501507759094238\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../Datasets/DROZY/videos_i8/11-2.mp4\")    \n",
    "#cap = cv2.VideoCapture(\"./Datasets/X/02/5.mov\")   \n",
    "#cap = cv2.VideoCapture(0)   \n",
    "#cap = cv2.VideoCapture(\"./Datasets/Fold4_part1/40/0.mp4\")   \n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()     # return status and image\n",
    "\n",
    "    #time.sleep(0.05)\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Can't retreive frame\")\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb = Image.fromarray(rgb)\n",
    "\n",
    "    try:\n",
    "        t = time.time()\n",
    "        (boxes, probs, landmarks) = mtcnn.detect(rgb, landmarks = True)\n",
    "        print(time.time() - t)\n",
    "        t = time.time()\n",
    "\n",
    "        cv2.rectangle(frame, (int(boxes[0][0]), int(boxes[0][1])), (int(boxes[0][2]), int(boxes[0][3])), (0, 255, 0), 1)\n",
    "        cv2.circle(frame, (int(landmarks[0][0][0]), int(landmarks[0][0][1])), 2, (255, 0, 0), 1)\n",
    "\n",
    "        d = int(0.2 * abs(boxes[0][0] - boxes[0][2]))\n",
    "        x1 = int(landmarks[0][0][0]) - d\n",
    "        x2 = int(landmarks[0][0][0]) + d \n",
    "        y1 = int(landmarks[0][0][1]) - d \n",
    "        y2 = int(landmarks[0][0][1]) + d \n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "        eye = frame[y1:y2, x1:x2]\n",
    "        eye = preprocess(eye)\n",
    "        pred = predict_eye_state(eye)\n",
    "\n",
    "        \"\"\" Do stuff with PERCLOS\"\"\"\n",
    "\n",
    "        if(pred == 0):\n",
    "            cv2.putText(frame, \"Closed\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"img\", frame)\n",
    "\n",
    "    # Exit window using \"q\" key\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[248.72688 130.89388 314.76306 220.96274]]\n"
     ]
    }
   ],
   "source": [
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[268.3033  167.30743]\n  [300.82962 166.44177]\n  [284.50043 180.28775]\n  [272.05902 203.69574]\n  [296.6056  203.28278]]]\n"
     ]
    }
   ],
   "source": [
    "print(landmarks)"
   ]
  }
 ]
}