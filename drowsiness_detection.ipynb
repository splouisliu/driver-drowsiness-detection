{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 512)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "\n",
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(6*6*32, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 6*6*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EyeClassifier(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1152, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# Load pre-trained face detector\n",
    "model_file = \"./Pretrained Detectors/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "config_file = \"./Pretrained Detectors/deploy.prototxt\"\n",
    "face_model = cv2.dnn.readNetFromCaffe(config_file, model_file)\n",
    "\n",
    "# Load pre-trained landmark predictor\n",
    "predictor = dlib.shape_predictor(\"./Pretrained Detectors/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load CNN eye classifier\n",
    "device = torch.device('cpu')\n",
    "eye_model = EyeClassifier()\n",
    "#eye_model.load_state_dict(torch.load(\"./Saved Models/model2.pt\", map_location = device))\n",
    "eye_model.load_state_dict(torch.load(\"./Saved Models/model_DataAug2.pt\", map_location = device))\n",
    "eye_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locates bounding box for a single face\n",
    "def detect_face(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    face_model.setInput(blob)\n",
    "    detections = face_model.forward()\n",
    "\n",
    "    (x1, y1, x2, y2) = 0, 0, 0, 0\n",
    "    max_confidence = 0\n",
    "\n",
    "    for i in range(detections.shape[2]):                          \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5 and confidence > max_confidence:      # Only considers predictions with > 0.5 confidence\n",
    "            (h, w) = img.shape[:2]\n",
    "            x1 = int(detections[0, 0, i, 3] * w)\n",
    "            y1 = int(detections[0, 0, i, 4] * h)\n",
    "            x2 = int(detections[0, 0, i, 5] * w)\n",
    "            y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "            max_confidence = confidence                           # If multiple faces are detected, only return the one with highest confidence\n",
    "\n",
    "    return dlib.rectangle(x1, y1, x2, y2), max_confidence\n",
    "\n",
    "\n",
    "# Locates bounding box for a single eye\n",
    "def detect_eye(img, face):\n",
    "    landmarks = predictor(img, face)\n",
    "\n",
    "    if landmarks.num_parts == 0:\n",
    "        return (0, 0, 0, 0), False\n",
    "    \n",
    "    \"\"\" Below is some random math I came up with to turn LEFT eye landmarks into a square box, feel free to change\"\"\"\n",
    "    x1 = landmarks.part(17).x                   \n",
    "    x2 = landmarks.part(21).x\n",
    "    d = abs(x2-x1)\n",
    "    k = d * 0.15\n",
    "\n",
    "    x1 = x1 - int(k/2)\n",
    "    x2 = x2 + int(k/2)\n",
    "    y1 = landmarks.part(19).y - int(k/2)\n",
    "    y2 = y1 + int(d+k)\n",
    "\n",
    "    return (x1, y1, x2, y2), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares an image for CNN eye classifier\n",
    "def preprocess(img):\n",
    "    t = transforms.Compose([transforms.Resize([32, 32]), \n",
    "                            transforms.ToTensor()]) \n",
    "                            \n",
    "    img = Image.fromarray(img).convert(\"L\")\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = t(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Predicts eye state given a single 1x24x24 tensor\n",
    "def predict_eye_state(img):\n",
    "    outputs = eye_model(img.unsqueeze(0))\n",
    "    prob = F.softmax(outputs, dim = 1)\n",
    "    pred = outputs.argmax(dim = 1).item()\n",
    "\n",
    "    #print(f\"Probabilities: ({prob[0][0]}, {prob[0][1]})\")\n",
    "    #print(\"Prediction:\", pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perclos_def(x):\n",
    "    if x < 0.075:\n",
    "        return \"Low drowsiness\"\n",
    "    elif x < 0.15:\n",
    "        return \"Moderate drowsiness\"\n",
    "    else:\n",
    "        return \"Severe drowsiness\"\n",
    "\n",
    "def kss_def(x):\n",
    "    if x == 1:\n",
    "        return \"Extremely Alert\"\n",
    "    elif x == 2:\n",
    "        return \"Very Alert\"\n",
    "    elif x == 3:\n",
    "        return \"Alert\"\n",
    "    elif x == 4:\n",
    "        return \"Rather Alert\"\n",
    "    elif x == 5:\n",
    "        return \"Neither alert nor sleepy\"\n",
    "    elif x == 6:\n",
    "        return \"Some signs of sleepiness\"\n",
    "    elif x == 7:\n",
    "        return \"Sleepy, but no effort to keep awake\"\n",
    "    elif x == 8:\n",
    "        return \"Sleepy, but some effort to keep awake\"\n",
    "    elif x == 9:\n",
    "        return \"Very sleepy. great effort to keep awake, fighting sleep\"\n",
    "    elif x == 10:\n",
    "        return \"Extremely sleepy, can't keep awake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(cap, kss = None):\n",
    "    # PERCLOS variables\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    sampling_t = 60                         # sampling interval in seconds\n",
    "    sampling_f = int(sampling_t * fps)      # sampling interval in frames\n",
    "\n",
    "    samples = []\n",
    "    perclos = []\n",
    "    num_closed = 0\n",
    "    counter = 0\n",
    "    t = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()     # return status and image\n",
    "        if not ret:\n",
    "            print(\"Can't retreive frame\")\n",
    "            break\n",
    "\n",
    "        #time.sleep(0.05)             # to see blinks clearly\n",
    "\n",
    "        # Face detection\n",
    "        face, confidence = detect_face(frame)\n",
    "\n",
    "        if confidence > 0:\n",
    "            # Draw face visual\n",
    "            cv2.rectangle(frame, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "\n",
    "            # Eye detection\n",
    "            (x1, y1, x2, y2), eye_found = detect_eye(frame, face)\n",
    "\n",
    "            if eye_found:\n",
    "                # Eye state classification\n",
    "                eye = frame[y1:y2, x1:x2]\n",
    "                eye = preprocess(eye)\n",
    "                pred = predict_eye_state(eye)\n",
    "\n",
    "\n",
    "                # Circular buffer to keep track of rolling predictions and PERCLOS values over sampling interval\n",
    "                if(pred == 0):\n",
    "                    num_closed += 1\n",
    "\n",
    "                if counter < sampling_f:\n",
    "                    samples.append(pred)\n",
    "                else:\n",
    "                    num_closed -= 1 - samples[counter % sampling_f]\n",
    "                    samples[counter % sampling_f] = pred\n",
    "                    perclos.append(num_closed/sampling_f)\n",
    "\n",
    "                # Draw eye visual\n",
    "                if(pred == 0):\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "                    cv2.putText(frame, \"Closed\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "                    cv2.putText(frame, \"Open\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "                counter += 1\n",
    "        \n",
    "        t += 1/fps\n",
    "\n",
    "        # Draw visuals\n",
    "        cv2.putText(frame, (\"Self Assessment: \" + kss_def(kss) + \" ({}/9)\".format(str(kss))) if kss else \"\", (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "        cv2.putText(frame, \"PERCLOS: \" + (\"{:.1%}\".format(perclos[-1]) if perclos else \"...\"), (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "        cv2.putText(frame, \"Prediction: \" + (perclos_def(perclos[-1]) if perclos else \"...\"), (0, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "        cv2.putText(frame, \"Time: \" + str(math.floor(t)), (0, frame.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow(\"img\", frame)\n",
    "\n",
    "        # Exit window using \"q\" key\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./Datasets/DROZY/videos_i8/1-2.mp4\")    \n",
    "#cap = cv2.VideoCapture(\"./Datasets/Fold4_part1/40/10.mp4\")   \n",
    "#cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "run(cap, kss = 3)"
   ]
  }
 ]
}