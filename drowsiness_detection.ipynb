{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0edd17d59108c9bdf549eba8a87bb201c398f5edc02ea5dc55defc458cb74fc3e",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "edd17d59108c9bdf549eba8a87bb201c398f5edc02ea5dc55defc458cb74fc3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 512)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test.py\nd:\\UofT Winter 2021\\APS360\\v4\\driver-drowsiness-detection-main\\driver-drowsiness-detection-main\\test.py\n..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# print(os.getcwd())\n",
    "print(os.path.basename(\"test.py\"))\n",
    "print(os.path.abspath(\"test.py\"))\n",
    "print(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EyeClassifier(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Load pre-trained face detector\n",
    "model_file = \"D://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Pretrained Detectors//res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "config_file = \"D://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Pretrained Detectors//deploy.prototxt\"\n",
    "face_model = cv2.dnn.readNetFromCaffe(config_file, model_file)\n",
    "\n",
    "# Load pre-trained landmark predictor\n",
    "predictor = dlib.shape_predictor(\"D://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Pretrained Detectors//shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load CNN eye classifier\n",
    "eye_model = EyeClassifier()\n",
    "eye_model.load_state_dict(torch.load(\"./Saved Models/model2.pt\"))\n",
    "eye_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locates bounding box for a single face\n",
    "def detect_face(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    face_model.setInput(blob)\n",
    "    detections = face_model.forward()\n",
    "\n",
    "    (x1, y1, x2, y2) = 0, 0, 0, 0\n",
    "    max_confidence = 0\n",
    "\n",
    "    for i in range(detections.shape[2]):                          \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5 and confidence > max_confidence:      # Only considers predictions with > 0.5 confidence\n",
    "            (h, w) = img.shape[:2]\n",
    "            x1 = int(detections[0, 0, i, 3] * w)\n",
    "            y1 = int(detections[0, 0, i, 4] * h)\n",
    "            x2 = int(detections[0, 0, i, 5] * w)\n",
    "            y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "            max_confidence = confidence                           # If multiple faces are detected, only return the one with highest confidence\n",
    "\n",
    "    return dlib.rectangle(x1, y1, x2, y2), max_confidence\n",
    "\n",
    "\n",
    "# Locates bounding box for a single eye\n",
    "def detect_eye(img, face):\n",
    "    landmarks = predictor(img, face)\n",
    "\n",
    "    if landmarks.num_parts == 0:\n",
    "        return (0, 0, 0, 0), False\n",
    "    \n",
    "    \"\"\" Below is some random math I came up with to turn LEFT eye landmarks into a square box, feel free to change\"\"\"\n",
    "    x1 = landmarks.part(17).x                   \n",
    "    x2 = landmarks.part(21).x\n",
    "    d = abs(x2-x1)\n",
    "    k = d * 0.15\n",
    "\n",
    "    x1 = x1 - int(k/2)\n",
    "    x2 = x2 + int(k/2)\n",
    "    y1 = landmarks.part(19).y - int(k/2)\n",
    "    y2 = y1 + int(d+k)\n",
    "\n",
    "    return (x1, y1, x2, y2), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares an image for CNN eye classifier\n",
    "def preprocess(img):\n",
    "    t = transforms.Compose([transforms.Resize([24, 24]), \n",
    "                            transforms.ToTensor()]) \n",
    "                            \n",
    "    img = Image.fromarray(img).convert(\"L\")\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = t(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# Predicts eye state given a single 1x24x24 tensor\n",
    "def predict_eye_state(img):\n",
    "    outputs = eye_model(img.unsqueeze(0))\n",
    "    prob = F.softmax(outputs, dim = 1)\n",
    "    pred = outputs.argmax(dim = 1).item()\n",
    "\n",
    "    #print(f\"Probabilities: ({prob[0][0]}, {prob[0][1]})\")\n",
    "    #print(\"Prediction:\", pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Sample testing code\n",
    "\n",
    "path = \"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Sample Pictures//open.jpg\"\n",
    "frame = cv2.imread(path)\n",
    "face, confidence = detect_face(frame)\n",
    "(x1, y1, x2, y2), eye_found = detect_eye(frame, face)\n",
    "if eye_found:\n",
    "    # Eye state classification\n",
    "    eye = frame[y1:y2, x1:x2]\n",
    "    eye = preprocess(eye)\n",
    "    pred = predict_eye_state(eye)\n",
    "    # perclos_list.append(pred)\n",
    "    print(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['3', '6', '7'], ['3', '7', '6'], ['2', '3', '4'], ['4', '8', '9'], ['3', '7', '8'], ['2', '3', '7'], ['0', '4', '9'], ['2', '6', '8'], ['2', '6', '8'], ['3', '6', '7'], ['4', '7', '7'], ['2', '5', '6'], ['6', '3', '7'], ['5', '7', '8']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# Read the KSS file (DROZY Dataset for testing)\n",
    "\n",
    "f = open(\"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY//KSS.txt\", \"r\")\n",
    "list1 = []\n",
    "string = f.read()\n",
    "string_mod = string.replace(\"\\n\", \",\")\n",
    "list1 = string_mod.split(\",\")\n",
    "for i in range(len(list1)):\n",
    "    list1[i] = list1[i].split(\" \")\n",
    "\n",
    "print(list1)\n",
    "\n",
    "def get_kss_drozy(filename, array):\n",
    "    # Assuming the filename -> \"1-2.mp4\" or \"11-2.mp4\"\n",
    "    if len(filename) == 7:\n",
    "        index1 = int(filename[0])\n",
    "        index2 = int(filename[2])\n",
    "    else:\n",
    "        index1 = int(filename[1])+10\n",
    "        index2 = int(filename[4])\n",
    "    return array[index1][index2]\n",
    "\n",
    "get_kss_drozy(\"1-2.mp4\", list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1800\n80\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY/videos_i8//1-2.mp4\")    \n",
    "#cap = cv2.VideoCapture(\"./Datasets/X/04/5.mp4\")   \n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "perclos_list = []\n",
    "closed_list = []\n",
    "\n",
    "counter = 0\n",
    "while cap.isOpened():\n",
    "    if counter > 1799:\n",
    "        break\n",
    "    ret, frame = cap.read()     # return status and image\n",
    "    if not ret:\n",
    "        print(\"Can't retreive frame\")\n",
    "        break\n",
    "    # print(ret)\n",
    "    # break\n",
    "\n",
    "    time.sleep(0.05)             # too see blinks clearly\n",
    "\n",
    "    # Face detection\n",
    "    face, confidence = detect_face(frame)\n",
    "    # print(confidence)\n",
    "    # break\n",
    "\n",
    "    if confidence > 0:\n",
    "\n",
    "        # Eye detection\n",
    "        (x1, y1, x2, y2), eye_found = detect_eye(frame, face)\n",
    "\n",
    "        if eye_found:\n",
    "            # Eye state classification\n",
    "            eye = frame[y1:y2, x1:x2]\n",
    "            eye = preprocess(eye)\n",
    "            pred = predict_eye_state(eye)\n",
    "            perclos_list.append(pred)\n",
    "\n",
    "            \"\"\"ADD KSS IF AND ELSE STATEMENTS\"\"\"\n",
    "\n",
    "            if(pred == 0):\n",
    "                cv2.putText(frame, \"Closed\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                closed_list.append(pred)\n",
    "\n",
    "        # Rectangle visuals\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        cv2.rectangle(frame, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "        confidence_txt = \"{:.2f}%\".format(confidence * 100)\n",
    "        cv2.putText(frame, confidence_txt, (face.left(), face.top()), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    # Display frame\n",
    "    # cv2.imshow(\"img\", frame)\n",
    "\n",
    "    # Exit window using \"q\" key\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(len(perclos_list))\n",
    "print(len(closed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY/videos_i8//1-2.mp4\"\n",
    "# kss_path = \"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY//KSS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kss(x):\n",
    "    '''\n",
    "    if and else statements of KSS\n",
    "    '''\n",
    "    if x == 1:\n",
    "        return \"Extremely Alert\"\n",
    "    elif x == 2:\n",
    "        return \"Very Alert\"\n",
    "    elif x == 3:\n",
    "        return \"Alert\"\n",
    "    elif x == 4:\n",
    "        return \"Rather Alert\"\n",
    "    elif x == 5:\n",
    "        return \"Neither alert nor sleepy\"\n",
    "    elif x == 6:\n",
    "        return \"Some signs of sleepiness\"\n",
    "    elif x == 7:\n",
    "        return \"Sleepy, but no effort to keep awake\"\n",
    "    elif x == 8:\n",
    "        return \"Sleepy, but some effort to keep awake\"\n",
    "    elif x == 9:\n",
    "        return \"Very sleepy. great effort to keep awake, fighting sleep\"\n",
    "    elif x == 10:\n",
    "        return \"Extremely sleepy, can't keep awake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_kss(vid_path, kss_path):\n",
    "    '''\n",
    "    Takes in the path of the video, path of the kss file. \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(vid_path)    \n",
    "    #cap = cv2.VideoCapture(\"./Datasets/X/04/5.mp4\")   \n",
    "    #cap = cv2.VideoCapture(0)\n",
    "\n",
    "    perclos_list = []\n",
    "    closed_list = []\n",
    "\n",
    "    # video_number = vid_path[]\n",
    "\n",
    "    if vid_path[-8] == \"/\":\n",
    "        per_index = int(vid_path[-7])-1\n",
    "        vid_index = int(vid_path[-5])-1\n",
    "    else:\n",
    "        per_index = 10+int(vid_path[-7])-1\n",
    "        vid_index = int(vid_path[-5])-1\n",
    "\n",
    "    counter = 0\n",
    "    while cap.isOpened():\n",
    "        if counter > 1799:\n",
    "            break\n",
    "        ret, frame = cap.read()     # return status and image\n",
    "        if not ret:\n",
    "            print(\"Can't retreive frame\")\n",
    "            break\n",
    "        time.sleep(0.05)             # too see blinks clearly\n",
    "        # Face detection\n",
    "        face, confidence = detect_face(frame)\n",
    "        if confidence > 0:\n",
    "            # Eye detection\n",
    "            (x1, y1, x2, y2), eye_found = detect_eye(frame, face)\n",
    "            if eye_found:\n",
    "                # Eye state classification\n",
    "                eye = frame[y1:y2, x1:x2]\n",
    "                eye = preprocess(eye)\n",
    "                pred = predict_eye_state(eye)\n",
    "                perclos_list.append(pred)\n",
    "                if(pred == 0):\n",
    "                    cv2.putText(frame, \"Closed\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                    closed_list.append(pred)\n",
    "            # Rectangle visuals\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "            cv2.rectangle(frame, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "            confidence_txt = \"{:.2f}%\".format(confidence * 100)\n",
    "            cv2.putText(frame, confidence_txt, (face.left(), face.top()), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1)\n",
    "        # Display frame\n",
    "        # cv2.imshow(\"img\", frame)\n",
    "\n",
    "        # Exit window using \"q\" key\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "        counter+=1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # add kss if and else and attach the kss function\n",
    "    perclos_deno = len(perclos_list)\n",
    "    perclos_nume = len(closed_list)\n",
    "    perclos_value = (perclos_nume / perclos_deno)\n",
    "\n",
    "    f = open(kss_path, \"r\")\n",
    "    list1 = []\n",
    "    string = f.read()\n",
    "    string_mod = string.replace(\"\\n\", \",\")\n",
    "    list1 = string_mod.split(\",\")\n",
    "    for i in range(len(list1)):\n",
    "        list1[i] = list1[i].split(\" \")\n",
    "\n",
    "    kss_val = int(list1[per_index][vid_index])\n",
    "\n",
    "    # add if and else for drowsineess\n",
    "    if perclos_value < 0.0375:\n",
    "        print(\"Model predicts: Low drowsiness\")\n",
    "    elif 0.0375 < perclos_value <= 0.075:\n",
    "        print(\"Model predicts: Low drowsiness\")\n",
    "    elif 0.075 < perclos_value <= 0.1125:\n",
    "         print(\"Model predicts: Moderate Drowsiness\")\n",
    "    elif 0.1125 < perclos_value <= 0.15:\n",
    "        print(\"Model predicts: Moderate Drowsiness\")\n",
    "    else:\n",
    "        print(\"Severe Drowsiness\")\n",
    "\n",
    "    kss_return_statement = kss(kss_val)\n",
    "\n",
    "    print(\"The KSS rating is \", kss_return_statement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-b49e8bac05fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkss_69\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY//KSS.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdetection_kss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_69\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkss_69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-6ba5a4d35d21>\u001b[0m in \u001b[0;36mdetection_kss\u001b[1;34m(vid_path, kss_path)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mlist1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mkss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mper_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvid_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# add if and else for drowsineess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "video_69 = \"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY/videos_i8//3-3.mp4\"\n",
    "kss_69 = \"d://UofT Winter 2021//APS360//v4//driver-drowsiness-detection-main//driver-drowsiness-detection-main//Datasets//DROZY//KSS.txt\"\n",
    "\n",
    "detection_kss(video_69, kss_69)\n",
    "\n",
    "# loop thru all the videos in drozy and output the perclos values"
   ]
  }
 ]
}