{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(6*6*32, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 6*6*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained face detector\n",
    "model_file = \"./Pretrained Detectors/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "config_file = \"./Pretrained Detectors/deploy.prototxt\"\n",
    "face_model = cv2.dnn.readNetFromCaffe(config_file, model_file)\n",
    "\n",
    "# Load pre-trained landmark predictor\n",
    "predictor = dlib.shape_predictor(\"./Pretrained Detectors/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load CNN eye classifier\n",
    "device = torch.device('cpu')\n",
    "eye_model = EyeClassifier()\n",
    "eye_model.load_state_dict(torch.load(\"./Saved Models/model_DataAug2.pt\", map_location = device))\n",
    "eye_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locates bounding box for a single face\n",
    "def detect_face(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    face_model.setInput(blob)\n",
    "    detections = face_model.forward()\n",
    "\n",
    "    (x1, y1, x2, y2) = 0, 0, 0, 0\n",
    "    max_confidence = 0\n",
    "\n",
    "    for i in range(detections.shape[2]):                          \n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.5 and confidence > max_confidence:      # Only considers predictions with > 0.5 confidence\n",
    "            (h, w) = img.shape[:2]\n",
    "            x1 = int(detections[0, 0, i, 3] * w)\n",
    "            y1 = int(detections[0, 0, i, 4] * h)\n",
    "            x2 = int(detections[0, 0, i, 5] * w)\n",
    "            y2 = int(detections[0, 0, i, 6] * h)\n",
    "\n",
    "            max_confidence = confidence                           # If multiple faces are detected, only return the one with highest confidence\n",
    "\n",
    "    return dlib.rectangle(x1, y1, x2, y2), max_confidence\n",
    "\n",
    "\n",
    "# Locates bounding box for a single eye\n",
    "def detect_eye(img, face):\n",
    "    landmarks = predictor(img, face)\n",
    "\n",
    "    if landmarks.num_parts == 0:\n",
    "        return (0, 0, 0, 0), False\n",
    "    \n",
    "    \"\"\" Below is some random math I came up with to turn LEFT eye landmarks into a square box, feel free to change\"\"\"\n",
    "    x1 = landmarks.part(17).x                   \n",
    "    x2 = landmarks.part(21).x\n",
    "    d = abs(x2-x1)\n",
    "    k = d * 0.15\n",
    "\n",
    "    x1 = x1 - int(k/2)\n",
    "    x2 = x2 + int(k/2)\n",
    "    y1 = landmarks.part(19).y - int(k/2)\n",
    "    y2 = y1 + int(d+k)\n",
    "\n",
    "    return (x1, y1, x2, y2), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares an image for CNN eye classifier\n",
    "def preprocess(img):\n",
    "    t = transforms.Compose([transforms.Resize([32, 32]), \n",
    "                            transforms.ToTensor()]) \n",
    "                            \n",
    "    img = Image.fromarray(img).convert(\"L\")\n",
    "    img = ImageOps.equalize(img)\n",
    "    img = t(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# Predicts eye state given a single 1x24x24 tensor\n",
    "def predict_eye_state(img):\n",
    "    outputs = eye_model(img.unsqueeze(0))\n",
    "    prob = F.softmax(outputs, dim = 1)\n",
    "    pred = outputs.argmax(dim = 1).item()\n",
    "\n",
    "    #print(f\"Probabilities: ({prob[0][0]}, {prob[0][1]})\")\n",
    "    #print(\"Prediction:\", pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map(x, in_min, in_max, out_min, out_max):\n",
    "    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "def perclos_to_kss(x):\n",
    "    if x <= 0.075:\n",
    "        return int(_map(x, 0, 0.075, 1, 5))\n",
    "    if x <= 0.15:\n",
    "        return int(_map(x, 0.075, 0.15, 6, 7))\n",
    "    else:\n",
    "        return int(_map(x, 0.15, 1, 8, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_kss(vid_path, kss_path):\n",
    "    '''\n",
    "    Takes in the path of the video, path of the kss file. \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(vid_path)    \n",
    "    #cap = cv2.VideoCapture(\"./Datasets/X/04/5.mp4\")   \n",
    "    #cap = cv2.VideoCapture(0)\n",
    "\n",
    "    perclos_list = []\n",
    "    closed_list = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 70 * cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()     # return status and image\n",
    "        if not ret:\n",
    "            print(\"Can't retreive frame\")\n",
    "            break\n",
    "\n",
    "        # Face detection\n",
    "        face, confidence = detect_face(frame)\n",
    "\n",
    "        if confidence > 0:\n",
    "            # Eye detection\n",
    "            (x1, y1, x2, y2), eye_found = detect_eye(frame, face)\n",
    "\n",
    "            if eye_found:\n",
    "                # Eye state classification\n",
    "                eye = frame[y1:y2, x1:x2]\n",
    "                eye = preprocess(eye)\n",
    "                eye_state = predict_eye_state(eye)\n",
    "                perclos_list.append(eye_state)\n",
    "\n",
    "                if(eye_state == 0):\n",
    "                    cv2.putText(frame, \"Closed\", (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                    closed_list.append(eye_state)\n",
    "\n",
    "                if(len(perclos_list) == 1800):\n",
    "                    break\n",
    "\n",
    "            # Rectangle visuals\n",
    "            #cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "            #cv2.rectangle(frame, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "            #confidence_txt = \"{:.2f}%\".format(confidence * 100)\n",
    "            #cv2.putText(frame, confidence_txt, (face.left(), face.top()), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1)\n",
    "        # Display frame\n",
    "        #cv2.imshow(\"img\", frame)\n",
    "        #print(len(closed_list))\n",
    "\n",
    "        # Exit window using \"q\" key\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # add kss if and else and attach the kss function\n",
    "    print(\"Total number of frames: \", len(perclos_list))\n",
    "    print(\"Closed eyes in the list: \", len(closed_list))\n",
    "    perclos_deno = len(perclos_list)\n",
    "    perclos_nume = len(closed_list)\n",
    "    perclos_value = (perclos_nume / perclos_deno)\n",
    "\n",
    "\n",
    "    f = open(kss_path, \"r\")\n",
    "    list1 = []\n",
    "    string = f.read()\n",
    "    string_mod = string.replace(\"\\n\", \",\")\n",
    "    list1 = string_mod.split(\",\")\n",
    "    for i in range(len(list1)):\n",
    "        list1[i] = list1[i].split(\" \")\n",
    "\n",
    "    \n",
    "    # video_number = vid_path[]\n",
    "    if vid_path[-8] == \"/\":\n",
    "        per_index = int(vid_path[-7])-1\n",
    "        vid_index = int(vid_path[-5])-1\n",
    "    else:\n",
    "        per_index = 9+int(vid_path[-7])\n",
    "        vid_index = int(vid_path[-5])-1\n",
    "\n",
    "    # Metrics\n",
    "    kss = int(list1[per_index][vid_index])\n",
    "    prediction = perclos_to_kss(perclos_value) \n",
    "\n",
    "    return kss, prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_69 = \"./Datasets/DROZY/videos_i8/1-1.mp4\"\n",
    "kss_69 = \"./Datasets/DROZY/KSS.txt\"\n",
    "\n",
    "kss, prediction = detection_kss(video_69, kss_69)\n",
    "\n",
    "# loop thru all the videos in drozy and output the perclos values in a list. Compare error with corresponding KSS values and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"./Datasets/DROZY/videos_i8/\"\n",
    "kss_path = \"./Datasets/DROZY/KSS.txt\"\n",
    "\n",
    "videos_1 = os.listdir(video_dir)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i, video in enumerate(videos_1):\n",
    "    video_path = video_dir + video\n",
    "    kss, prediction = detection_kss(video_path, kss_path)\n",
    "    result.append((kss, prediction))\n",
    "\n",
    "    print(f\"Video {i} finished\")\n",
    "    print(f\"\\tKSS: {kss}, Prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = []\n",
    "ps = []\n",
    "err = []\n",
    "n = 18\n",
    "x = list(range(1, n+1))\n",
    "\n",
    "for i,(kss, pred) in enumerate(result):\n",
    "    if i == n:\n",
    "        break\n",
    "\n",
    "    ks.append(kss)\n",
    "    ps.append(pred)\n",
    "    err.append(abs((pred-kss)/kss))\n",
    "\n",
    "\n",
    "# Plot prediction vs self-assessment\n",
    "df = pd.DataFrame(list(zip(x, ks, ps)), columns = [\"Video\", \"Self Assessment\", \"Prediction\"])\n",
    "df.set_index(\"Video\", inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel(\"Karolinska Sleepiness Scale\")\n",
    "df.plot.bar(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.plot(x, err, marker = \"o\")\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Videos\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "avg_err = sum(err)/n\n",
    "print(avg_err)"
   ]
  }
 ]
}